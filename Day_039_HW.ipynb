{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Day_039_HW.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semishen/ML100Days/blob/master/Day_039_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBM7Ndg-g0bu",
        "colab_type": "text"
      },
      "source": [
        "## [作業重點]\n",
        "清楚了解 L1, L2 的意義與差異為何，並了解 LASSO 與 Ridge 之間的差異與使用情境"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58M6Fzdfg0bv",
        "colab_type": "text"
      },
      "source": [
        "## 作業"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpM6qC2Gg0bw",
        "colab_type": "text"
      },
      "source": [
        "請閱讀相關文獻，並回答下列問題\n",
        "\n",
        "[脊回歸 (Ridge Regression)](https://blog.csdn.net/daunxx/article/details/51578787)\n",
        "[Linear, Ridge, Lasso Regression 本質區別](https://www.zhihu.com/question/38121173)\n",
        "\n",
        "### Q1: LASSO 回歸可以被用來作為 Feature selection 的工具，請了解 LASSO 模型為什麼可用來作 Feature selection\n",
        "### A1: LASSO 基於 L1 正則，隨著 alpha 的提升數值為0的參數數量隨之提升，而參數為0的特徵可以視為對模型沒有影響力，理當剔除，因此 LASSO 具有 Feature Selection 的功能。\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "### Q2: 當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題嗎?\n",
        "### A2: 可以。當自變數存在高度共線性時，模型對 noise 的敏感度會提高，Ridge Regression 基於 L2 正則，可以減緩參數的劇烈變動，降低 noise 的影響性。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNo7hdlSg0bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}